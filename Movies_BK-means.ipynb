{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Movies datasets analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#VectorAssembler provides transformer to convert Dataframe columns into vectors\n",
    "#StandarScalar is for useful fetures selection using technics like (ChiSquare)\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "\n",
    "# Bisecting k-means clustering\n",
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# useful functions for String datatype analysis\n",
    "#StringIndexer provides transformer to convert string labels into numerical values\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, RegexTokenizer, StopWordsRemover\n",
    "\n",
    "# multiclass classification Metrics library, knowing that movies are clustered based on multiple criterion\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#Processing so;plex structures (i.e genre,)\n",
    "#Useful methods for date manipulations with pyspark \n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"film\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load data from the data1 repertory location already uploaded in HDFS\n",
    "#movies-metadata\n",
    "meta = spark.read.csv(\"./data1/movies_metadata.csv\",\n",
    "                       header = True, inferSchema = True)\n",
    "\n",
    "#ratings\n",
    "rati = spark.read.csv(\"./data1/ratings_small.csv\",\n",
    "                       header = True, inferSchema = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- adult: string (nullable = true)\n",
      " |-- belongs_to_collection: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- spoken_languages: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- video: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- vote_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bisecting K-means\n",
    "\n",
    "Ratings dataset represents a historical data source suitable for use and track users to build a CFRS. Thus, merging the latter dataset with a rich movie description within movies_metadata (see previous schema) helps to give more insights on users' preferences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- adult: string (nullable = true)\n",
      " |-- belongs_to_collection: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- spoken_languages: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- video: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- vote_count: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pyspark \"join\" function\n",
    "\n",
    "#we neeed to agree on 'movie ID' as 'id' on both datasets\n",
    "rati = rati.selectExpr(\"userId as userId\", \"movieId as id\", \"rating as rating\", \"timestamp as timestamp\")\n",
    "movi_rati = meta.join(rati, on=['id'], how='inner') \n",
    "movi_rati.printSchema()\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the datasets for PySpark ML \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting release dates to spark datetime\n",
    "func = udf (lambda x: datetime.strptime(x, '%m/%%d/%Y'), DateType())\n",
    "movi_rati = movi_rati.withColumn(\"release_date\", func(col(\"release_date\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+-----------------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "|                id|              budget|       popularity|             revenue|        vote_count|      vote_average|            userId|           timestamp|\n",
      "+------------------+--------------------+-----------------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "|             44925|               44678|            41364|               40461|             41775|             40643|             44925|               44925|\n",
      "| 6006.031761264895|1.9859276239357177E7|8.153184489652464| 7.902478949780445E7| 654.7698384201086|114753.16447609093| 345.8632164718976|1.0899410248034725E9|\n",
      "|15930.725435031307| 3.798504925606181E7|6.880673692190476|1.8142134682936063E8|1215.9350993372047| 5512893.569973916|194.84668982664172|1.8803306535208604E8|\n",
      "|          1.574392|                 0.0|              0.0|                 0.0|               0.0|               0.0|               1.0|        7.89652009E8|\n",
      "|          160718.0|               3.8E8|       140.950236|       1.845034188E9|           12269.0|      2.96655431E8|             671.0|       1.476623282E9|\n",
      "+------------------+--------------------+-----------------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visualize some data from the combines dataset\n",
    "movi_rati.describe().select(\"id\", \"budget\", \"popularity\", \"revenue\", \"vote_count\", \"vote_average\", \"userId\", \"timestamp\").show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting useful features for our model\n",
    "movi_rati = movi_rati.select(\"id\", \"popularity\", \"vote_count\", \"vote_average\", \"userId\", \"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- vote_count: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movi_rati.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "[trainingData, testData] = movi_rati.randomSplit([0.7, 0.3])\n",
    "\n",
    "#vector assembler to transform feature columns into vector\n",
    "assembler = VectorAssembler(inputCols = [\"popIndexed\", \"uiIndexed\", \"vaIndexed\", \"vcIndexed\", \"idIndexed\"],\n",
    "                            outputCol = \"features\")\n",
    "\n",
    "#The VectorIndexer will automatically transform categorical attributes to numerical values\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=50)\n",
    "\n",
    "\n",
    "## It is important to handle string indexer exceptions to fit the pipeliner and transform the raw data #####\n",
    "ratIndex = StringIndexer(inputCol=\"rating\", outputCol=\"label\")\n",
    "ratIndex.setHandleInvalid(\"keep\")\n",
    "\n",
    "popIndex = StringIndexer(inputCol=\"popularity\", outputCol=\"popIndexed\")\n",
    "popIndex.setHandleInvalid(\"keep\")\n",
    "\n",
    "idIndex = StringIndexer(inputCol=\"id\", outputCol=\"idIndexed\")\n",
    "idIndex.setHandleInvalid(\"keep\")\n",
    "\n",
    "vcIndex = StringIndexer(inputCol=\"vote_count\", outputCol=\"vcIndexed\")\n",
    "vcIndex.setHandleInvalid(\"keep\")\n",
    "\n",
    "vaIndex= StringIndexer(inputCol=\"vote_average\", outputCol=\"vaIndexed\")\n",
    "vaIndex.setHandleInvalid(\"keep\")\n",
    "\n",
    "uiIndex= StringIndexer(inputCol=\"userId\", outputCol=\"uiIndexed\")\n",
    "uiIndex.setHandleInvalid(\"keep\")\n",
    "                       \n",
    "# estimator for bisecting k-means model\n",
    "bis-km = BisectingKMeans().setK(6).setSeed(1)\n",
    "\n",
    "# ML pipeline to assemble transformers and estimators\n",
    "pipeline = Pipeline(stages=[popIndex, uiIndex, vaIndex, vcIndex, ratIndex, idIndex, assembler, bis-km])                       \n",
    "\n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+------+------+----------+---------+---------+---------+-----+---------+--------------------+----------+\n",
      "|  id|          popularity|          vote_count|        vote_average|userId|rating|popIndexed|uiIndexed|vaIndexed|vcIndexed|label|idIndexed|            features|prediction|\n",
      "+----+--------------------+--------------------+--------------------+------+------+----------+---------+---------+---------+-----+---------+--------------------+----------+\n",
      "| 101| he becomes the u...|Leon: The Profess...|If you want a job...|    56|   4.0|      48.0|    242.0|     33.0|     50.0|  0.0|     52.0|[48.0,242.0,33.0,...|         4|\n",
      "| 101| he becomes the u...|Leon: The Profess...|If you want a job...|    83|   3.5|      48.0|    184.0|     33.0|     50.0|  4.0|     52.0|[48.0,184.0,33.0,...|         3|\n",
      "| 101| he becomes the u...|Leon: The Profess...|If you want a job...|   388|   4.0|      48.0|     20.0|     33.0|     50.0|  0.0|     52.0|[48.0,20.0,33.0,5...|         1|\n",
      "| 101| he becomes the u...|Leon: The Profess...|If you want a job...|   434|   5.0|      48.0|    150.0|     33.0|     50.0|  1.0|     52.0|[48.0,150.0,33.0,...|         3|\n",
      "| 101| he becomes the u...|Leon: The Profess...|If you want a job...|   624|   3.5|      48.0|     13.0|     33.0|     50.0|  4.0|     52.0|[48.0,13.0,33.0,5...|         1|\n",
      "|1024|            9.438042|                 299|                 6.9|   188|   3.0|      94.0|    192.0|      7.0|     37.0|  2.0|     93.0|[94.0,192.0,7.0,3...|         3|\n",
      "|  11|           42.149697|                6778|                 8.1|    57|   5.0|       8.0|     75.0|     12.0|      8.0|  1.0|      8.0|[8.0,75.0,12.0,8....|         0|\n",
      "|  11|           42.149697|                6778|                 8.1|    58|   5.0|       8.0|    381.0|     12.0|      8.0|  1.0|      8.0|[8.0,381.0,12.0,8...|         5|\n",
      "|  11|           42.149697|                6778|                 8.1|    59|   2.5|       8.0|    259.0|     12.0|      8.0|  6.0|      8.0|[8.0,259.0,12.0,8...|         4|\n",
      "|  11|           42.149697|                6778|                 8.1|    63|   3.5|       8.0|    300.0|     12.0|      8.0|  4.0|      8.0|[8.0,300.0,12.0,8...|         4|\n",
      "|  11|           42.149697|                6778|                 8.1|   121|   4.0|       8.0|    139.0|     12.0|      8.0|  0.0|      8.0|[8.0,139.0,12.0,8...|         2|\n",
      "|  11|           42.149697|                6778|                 8.1|   182|   5.0|       8.0|    104.0|     12.0|      8.0|  1.0|      8.0|[8.0,104.0,12.0,8...|         2|\n",
      "|  11|           42.149697|                6778|                 8.1|   219|   4.0|       8.0|    270.0|     12.0|      8.0|  0.0|      8.0|[8.0,270.0,12.0,8...|         4|\n",
      "|  11|           42.149697|                6778|                 8.1|   235|   3.5|       8.0|     98.0|     12.0|      8.0|  4.0|      8.0|[8.0,98.0,12.0,8....|         2|\n",
      "|  11|           42.149697|                6778|                 8.1|   268|   3.5|       8.0|     60.0|     12.0|      8.0|  4.0|      8.0|[8.0,60.0,12.0,8....|         0|\n",
      "|  11|           42.149697|                6778|                 8.1|   294|   3.0|       8.0|     22.0|     12.0|      8.0|  2.0|      8.0|[8.0,22.0,12.0,8....|         0|\n",
      "|  11|           42.149697|                6778|                 8.1|   311|   5.0|       8.0|      3.0|     12.0|      8.0|  1.0|      8.0|[8.0,3.0,12.0,8.0...|         0|\n",
      "|  11|           42.149697|                6778|                 8.1|   319|   4.0|       8.0|    531.0|     12.0|      8.0|  0.0|      8.0|[8.0,531.0,12.0,8...|         5|\n",
      "|  11|           42.149697|                6778|                 8.1|   380|   2.0|       8.0|     56.0|     12.0|      8.0|  3.0|      8.0|[8.0,56.0,12.0,8....|         0|\n",
      "|  11|           42.149697|                6778|                 8.1|   390|   5.0|       8.0|     72.0|     12.0|      8.0|  1.0|      8.0|[8.0,72.0,12.0,8....|         0|\n",
      "+----+--------------------+--------------------+--------------------+------+------+----------+---------+---------+---------+-----+---------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "#test the classification model using the test data\n",
    "prediction = model.transform(testData)\n",
    "\n",
    "prediction.select('id', 'userId', '', '').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features with standard scaler \n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "stdscaler = StandardScaler().setInputCol(\"features\").setOutputCol(\"normalized_features\")\n",
    "prediction=stdscaler.fit(prediction).transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------+------+-----+----------+\n",
      "|Selected_features                                                                                  |userId|label|prediction|\n",
      "+---------------------------------------------------------------------------------------------------+------+-----+----------+\n",
      "|[1.41475420797037,1.3583889992187068,3.440803240680316,1.5824534467200047,1.5278703946488534]      |56    |0.0  |4         |\n",
      "|[1.41475420797037,1.032824693620835,3.440803240680316,1.5824534467200047,1.5278703946488534]       |83    |4.0  |3         |\n",
      "|[1.41475420797037,0.11226355365443857,3.440803240680316,1.5824534467200047,1.5278703946488534]     |388   |0.0  |1         |\n",
      "|[1.41475420797037,0.8419766524082893,3.440803240680316,1.5824534467200047,1.5278703946488534]      |434   |1.0  |3         |\n",
      "|[1.41475420797037,0.07297130987538508,3.440803240680316,1.5824534467200047,1.5278703946488534]     |624   |4.0  |1         |\n",
      "|[2.7705603239419747,1.0777301150826104,0.7298673540837034,1.1710155505728035,2.7325374365835264]   |188   |2.0  |3         |\n",
      "|[0.23579236799506167,0.42098832620414467,1.2512011784292059,0.25319255147520076,0.2350569837921313]|57    |1.0  |0         |\n",
      "|[0.23579236799506167,2.1386206971170547,1.2512011784292059,0.25319255147520076,0.2350569837921313] |58    |1.0  |5         |\n",
      "|[0.23579236799506167,1.4538130198249797,1.2512011784292059,0.25319255147520076,0.2350569837921313] |59    |6.0  |4         |\n",
      "|[0.23579236799506167,1.6839533048165787,1.2512011784292059,0.25319255147520076,0.2350569837921313] |63    |4.0  |4         |\n",
      "+---------------------------------------------------------------------------------------------------+------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# chisquareselector for relevant features selection\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "chisq = ChiSqSelector(featuresCol='normalized_features', outputCol='Selected_features', labelCol='label',\n",
    "                   fpr=0.005)\n",
    "#predictions = chi.fit(predictions).transform(train)\n",
    "test=chisq.fit(prediction).transform(prediction)\n",
    "test.select(\"Selected_features\", \"userId\", \"label\", \"prediction\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Error = 0.829102\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol = 'label', predictionCol = 'prediction', metricName='accuracy')\n",
    "\n",
    "p = prediction.withColumn(\"prediction\", prediction[\"prediction\"].cast(\"double\"))\n",
    "\n",
    "accuracy = evaluator.evaluate(p)\n",
    "\n",
    "print(\"Classification Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shutdown the spark session\n",
    "\n",
    "It is necessary to shutdown the spark session once all tasks are completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-07bf254f7f61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#invoke the method stop to shutdown the spark session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "#invoke the method stop to shutdown the spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
